# -*- coding: utf-8 -*-
"""AIOT_Edward_David_Thoronka_2120246052_Classification_(2) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rfASzzNJvmovHrBo_CjhoLFe8LytKRmZ

# . Importing Libraries and Setting up Device:
"""

!pip install torch torchvision

"""import the labires"""

import torch
import matplotlib.pyplot as plt
import numpy as np
from google.colab import drive
from PIL import Image
import PIL.ImageOps
import torch.nn.functional as F
from torch import nn
from torchvision import datasets, transforms

"""# Setting up Device (Define the cuda or cpu)"""

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

"""Defining the Residual Block:"""

# Create a ResidualBlock class
class ResidualBlock(nn.Module):
    def __init__(self, inchannel, outchannel, stride=1):
        super(ResidualBlock, self).__init__()
        self.left = nn.Sequential(
            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(outchannel),
            nn.ReLU(inplace=True),
            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(outchannel)
        )
        self.shortcut = nn.Sequential()
        if stride != 1 or inchannel != outchannel:
            self.shortcut = nn.Sequential(
                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(outchannel)
            )

      # Foward function for the training

    def forward(self, x):
        out = self.left(x)
        out = out + self.shortcut(x)
        out = F.relu(out)

        return out

"""# Defining the ResNet Class:

"""

#Create the ReNet Class
class ResNet(nn.Module):
    def __init__(self, ResidualBlock, num_classes=10):
        super(ResNet, self).__init__()
        self.inchannel = 64
        self.conv1 = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU()
        )
        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)
        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)
        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)
        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)
        self.fc = nn.Linear(512, num_classes)

    def make_layer(self, block, channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.inchannel, channels, stride))
            self.inchannel = channels
        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv1(x)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = F.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out

"""# Model Instantiation and Hyperparameters:

"""

def ResNet18():
    return ResNet(ResidualBlock)

#set hyperparameter
EPOCH = 10
pre_epoch = 0
BATCH_SIZE = 128
LR = 0.001

"""#Data Loading and Preprocessing:

"""

#prepare dataset loading and preprocessing
transform_train = transforms.Compose([
    transforms.Resize((32,32)),
    transforms.ToTensor(),
    transforms.Normalize((0.1307), (0.3081))
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307), (0.3081))
])

#  Loading the Dataset

training_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)
training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

validation_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)
validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=128, shuffle=False)

"""# Printing of the DataSet"""

print(len(training_dataset))
print(len(validation_dataset))

"""# Image convertion"""

def im_convert(tensor):
  image = tensor.clone().detach().numpy()
  image = image.squeeze()
  image = image * 0.5 + 0.5
  image = image.clip(0,1)
  return image

"""# Define the classes"""

classes = ('zero','one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine')

# Display images
training_loader_iter = iter(training_loader)
images, labels = next(training_loader_iter)

fig = plt.figure(figsize=(25,4))
for idx in np.arange(20):
  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
  plt.imshow(im_convert(images[idx].cpu()), cmap='gray')
  ax.set_title(classes[labels[idx].item()])

"""# Model Training and Evaluation:"""

def ResNet18():
        return ResNet(ResidualBlock)

#define ResNet18
model = ResNet18().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)

"""#Visualization and Results:"""

# Here the graph show the TrainingLoss and the validation accuarcy
plt.plot(running_loss_histroy, label='training loss')
plt.plot([val.cpu() for val in val_running_corrects_history], label='validation accuracy')
plt.legend()

running_loss_histroy = []
running_corrects_history = []
val_running_loss_history = []
val_running_corrects_history = []

for n in range(EPOCH):
  running_loss = 0.0
  running_corrects = 0.0
  val_running_loss = 0.0
  val_running_corrects = 0.0

  for inputs, labels in training_loader:
    inputs = inputs.to(device)
    labels = labels.to(device)
    outputs = model(inputs)
    loss = criterion(outputs, labels)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    _, preds = torch.max(outputs, 1)
    running_loss += loss.item()
    running_corrects += torch.sum(preds == labels.data)

  else:
    with torch.no_grad():
      for val_inputs, val_labels in validation_loader:
        val_inputs = val_inputs.to(device)
        val_labels = val_labels.to(device)
        val_outputs = model(val_inputs)
        val_loss = criterion(val_outputs, val_labels)

        _, val_preds = torch.max(val_outputs, 1)
        val_running_loss += val_loss.item()
        val_running_corrects += torch.sum(val_preds == val_labels.data)

    epoch_loss = running_loss/len(training_loader)
    epoch_acc = running_corrects.float()/len(training_loader)
    running_loss_histroy.append(epoch_loss)
    running_corrects_history.append(epoch_acc)

    val_epoch_loss = val_running_loss/len(validation_loader)
    val_epoch_acc = val_running_corrects.float()/len(validation_loader)
    val_running_loss_history.append(val_epoch_loss)
    val_running_corrects_history.append(val_epoch_acc)

    print('EPOCH-OUT-PUT :', (n+1))
    print('training loss: {:.4f}, acc {:.4f}'.format(epoch_loss, epoch_acc.item()))
    print('validation loss: {:.4f}, val_acc {:.4f}'.format(val_epoch_loss, val_epoch_acc.item()))

"""Plot the traing history (Loss and Acc)"""

# Here is the graph that show the Training accuracy and the validation accuracy
plt.plot([val.cpu() for val in running_corrects_history], label='Training accuracy')
plt.plot([val.cpu() for val in val_running_corrects_history], label='Validation accuracy')
plt.legend()

"""# Displaying of the trained images"""

# Display images with the validation lodder
training_loader_iter = iter(validation_loader)
images, labels = next(training_loader_iter)
images = images.to(device)
labels = labels.to(device)
images_ = images.view(images.shape[0], -1)
output = model(images)
_, preds = torch.max(output, 1)

# Create figure of the images displaced
fig = plt.figure(figsize=(15,4))
for idx in np.arange(10):
  ax = fig.add_subplot(2, 5, idx+1, xticks=[], yticks=[])
  plt.imshow(im_convert(images[idx].cpu()), cmap='gray')
  ax.set_title("{} ({})".format(str(classes[preds[idx].item()]), str(classes[labels[idx].item()]), color = 'green' if preds[idx]==labels[idx] else 'red'))